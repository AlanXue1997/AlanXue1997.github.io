<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1" /><title>Machine Learning I</title><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@XueZhonghao" /><meta name="twitter:title" content="Machine Learning I" /><meta name="twitter:description" content="在学习Andrew Ng的机器学习课程Machine Learning，上了这个课之后感觉，这才叫MOOC好不好！老师很认真的在讲，而且讲的特别细致，连不会微积分都没关系(￣▽￣)”"><meta name="description" content="在学习Andrew Ng的机器学习课程Machine Learning，上了这个课之后感觉，这才叫MOOC好不好！老师很认真的在讲，而且讲的特别细致，连不会微积分都没关系(￣▽￣)”"><meta name="google-site-verification" content="epFgX0s_0RM3CdjwFcsewfXzPov2g8s9ZBOLyaIUH-o"><link rel="shortcut icon" href="/assets/totora.png"> <!--<link rel="icon" href="/assets/totora.png">--><link rel="apple-touch-icon" href="/assets/touch-icon.png"><link rel="stylesheet" href="//code.cdn.mozilla.net/fonts/fira.css"><link rel="stylesheet" href="/assets/core.css"><link rel="stylesheet" href="/assets/prism.css"><link rel="canonical" href="/notes/Machine-Learning-1"><link rel="alternate" type="application/atom+xml" title="AlanXue's blog" href="/feed.xml" /></head><body><aside class="logo"> <a href="/"> <img src="/assets/Totora2.png"> </a> <span class="logo-prompt">Back to Home</span></aside><!--src="http://www.gravatar.com/avatar/742cf6353760888dd24b7f22843cca55.png?s=80" class="gravatar" --><main> <noscript><style> article .footnotes { display: block; }</style></noscript><article><div class="center"><h1>Machine Learning I</h1><time>June 9, 2016</time></div><div class="divider"></div><p>在学习Andrew Ng的机器学习课程<a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a>，上了这个课之后感觉，这才叫MOOC好不好！老师很认真的在讲，而且讲的特别细致，连不会微积分都没关系(￣▽￣)”</p><p>前两周的课程讲了线性回归的两种方法，一是梯度下降法（Gradient descent），二是正规方程（Normal Equation），两者各有利弊。</p><table><thead><tr><th style="text-align: left">梯度下降法</th><th style="text-align: left">正规方程</th></tr></thead><tbody><tr><td style="text-align: left">只能趋近于最优解</td><td style="text-align: left">最优解√</td></tr><tr><td style="text-align: left">需要选择合适的α</td><td style="text-align: left">有通式求解√</td></tr><tr><td style="text-align: left">O(n*iterations)√</td><td style="text-align: left">O(n^3)</td></tr><tr><td style="text-align: left">应用范围较广√</td><td style="text-align: left">只能用于线性回归</td></tr></tbody></table><p>根据Andrew老师的建议，当n（feature的种类）超过10000时，才应该考虑梯度下降法，否则用正规方程通常更好。</p><div class="divider"></div><h2 id="section">应用</h2><p>用线性回归分析了一下学院上学期的成绩。</p><p>最可能会有相关关系的，是工数和线数。用<strong>正规方程</strong>求解，得到下图：</p><p><img src="/assets/Cal_Lin.png" /></p><p>θ =</p><blockquote> <center> | -3.5127 |<br /> | 0.9836 |<br /> </center></blockquote><p>果然，θ2=0.98，说明这两门学科的分数是很有联系的。同时也看出了，工数的分数还是普遍高于线数的。有可能是因为工数的学分高，也有可能是确实线数比工数难一些吧。</p><p>之后用<strong>梯度下降法</strong>求解，得到了下图：</p><p><img src="/assets/Gra_Des.png" /></p><p>θ =</p><blockquote> <center> | 0.0110 |<br /> | 0.9417 |<br /> </center></blockquote><p>α =</p><blockquote> <center> 0.00001 </center></blockquote><p>Andrew老师说将来会有方法自动选择α。但目前来看，这个α还是很难选的。而且这个梯度下降法，Cost的下降速度的下降速度（下降加速度）是很大的，只要α是能用的，差不多二三十次就能精确到个位了，但即使到了1000次（100次和1000次差别不大）还相差了0.8左右。可能真正使用梯度下降法的时候得迭代十万、百万次的。</p><div class="divider"></div><h2 id="section-1">其他</h2><p>突然想看看，如果是没什么关系的数据，线性回归会得到什么结果呢？</p><p>于是，我计算了一下工数和军事理论的关系：</p><p><img src="/assets/Cal_Mil.png" /></p><p>看到这个图的第一印象，这么分散啊，但看了一眼Cost，才4.8！看了一眼坐标轴，我想到了前两天知乎上看到的一个问题：<a href="https://www.zhihu.com/question/19578400">「数据会说谎」的真实例子有哪些？</a>今天碰见这张图，果然很有误导性啊，于是赶紧</p><div class="highlighter-rouge"><pre class="highlight"><code><span class="nb">set</span><span class="p">(</span><span class="nb">gca</span><span class="p">,</span> <span class="s1">'XLim'</span><span class="p">,</span> <span class="p">[</span><span class="mi">40</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">'YLim'</span><span class="p">,</span> <span class="p">[</span><span class="mi">40</span> <span class="mi">100</span><span class="p">]);</span>
</code></pre></div><p>这样得到的图就合理多了：</p><p><img src="/assets/Cal_Mil(2).png" /></p><p>这张图还让我明白，反应两个数据相关程度的并不是Cost的大小，而应该是对应的θ，θ越接近0，就越没关系。比如，当把工数和军理两科互换之后，Cost产生了很大的变化，但两者θ2都不大。</p><p><img src="/assets/Mil_Cal.png" /></p><p>ps：其实我尝试过各种各样的组合，已经多个科目的组合，θ经常会降到0.1左右，甚至0.01左右，但从来没有小于0过。这说明，整体看来，“好学生”们，就算是那种凭运气的军理，也会比普通学生分数高一写，这应该就是态度不同的体现吧。</p><div class="divider"></div></article><div class="back"> <a href="/">Back</a></div></main></body></html>